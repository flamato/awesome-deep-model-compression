# awesome-deep-model-compression
List of papers related to ML and DL model compression for embedded devices(Mobiles, IoT)

## Machine Learning
- 2017 [Resource-efficient Machine Learning in 2 KB RAM for the Internet of Things](http://proceedings.mlr.press/v70/kumar17a.html)

## Deep Learning
- ### Pruning
  - 1993 [Second order derivatives for network pruning: Optimal brain surgeon](http://papers.nips.cc/paper/647-second-order-derivatives-for-network-pruning-optimal-brain-surgeon.pdf)
  - 2015 NIPS [Learning both weights and connections for efficient neural network](http://papers.nips.cc/paper/5784-learning-both-weights-and-connections-for-efficient-neural-network)

- ### Quantization

- ### Prunig and Quantization
  - 2015 [Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding](https://arxiv.org/abs/1510.00149)
  
- ### Binarization

- ### Low-Rank-Factorization

- ### Knowledge Distilation

- ### Stucture

- ### Sparse

- ### Others


